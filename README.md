# AI Voice Assistant

An AI-powered voice and chat assistant for GetMyQuotation platform, built with LiveKit for real-time voice communication and Azure OpenAI for intelligent conversational responses.

## ğŸ¯ Project Overview

This project provides a customer support assistant that helps users understand how to get quotes for interior work and furniture through the GetMyQuotation platform. The assistant is available in two modes:

- **Voice Assistant**: Real-time voice conversation using LiveKit
- **Chatbot**: Text-based chat interface using Azure OpenAI

## ğŸ“ Project Structure

```
Ai_voice_assistant/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ livekit-voice-agent/     # LiveKit voice agent implementation
â”‚   â”‚   â”œâ”€â”€ agent.py              # Main agent logic
â”‚   â”‚   â”œâ”€â”€ pyproject.toml        # Python dependencies (uv)
â”‚   â”‚   â”œâ”€â”€ uv.lock               # Lock file
â”‚   â”‚   â””â”€â”€ .env.local            # Environment variables (create this)
â”‚   â””â”€â”€ token-server/             # FastAPI server for tokens and chat API
â”‚       â”œâ”€â”€ server.py             # Token generation and chat endpoints
â”‚       â””â”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ frontend/                      # React frontend application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx               # Main app component
â”‚   â”‚   â”œâ”€â”€ HomePage.jsx          # Landing page
â”‚   â”‚   â”œâ”€â”€ Chatbot.jsx           # Chat interface component
â”‚   â”‚   â”œâ”€â”€ VoiceAssistant.jsx   # Voice assistant component
â”‚   â”‚   â””â”€â”€ *.css                 # Component styles
â”‚   â”œâ”€â”€ index.html                # HTML entry point
â”‚   â”œâ”€â”€ package.json              # Node.js dependencies
â”‚   â””â”€â”€ vite.config.js            # Vite configuration
â””â”€â”€ README.md                      # This file
```

## âœ¨ Features

- **Real-time Voice Communication**: Powered by LiveKit for high-quality audio streaming
- **Intelligent Chat Interface**: Text-based chatbot using Azure OpenAI
- **Multi-modal Support**: Switch between voice and chat modes
- **Advanced Voice Processing**: 
  - Noise cancellation (BVC)
  - Voice activity detection (Silero VAD)
  - Turn detection for natural conversations
  - Speech-to-text (AssemblyAI Universal Streaming)
  - Text-to-speech (Cartesia Sonic)
- **Customer Support Focus**: Specialized for GetMyQuotation platform queries

## ğŸ”§ Prerequisites

- **Python 3.11** or **3.12** (for backend services)
- **Node.js 18+** and **npm** (for frontend)
- **uv** (Python package manager) - Install from [https://github.com/astral-sh/uv](https://github.com/astral-sh/uv)
- **LiveKit Cloud** account or self-hosted LiveKit server
- **Azure OpenAI** account with API access
- **OpenAI API Key** (for voice agent LLM)

## ğŸ“‹ Environment Variables

Create a `.env.local` file in `backend/livekit-voice-agent/` with the following variables:

### LiveKit Configuration
```env
LIVEKIT_API_KEY=your_livekit_api_key
LIVEKIT_API_SECRET=your_livekit_api_secret
LIVEKIT_URL=wss://your-livekit-server.com
```

### Azure OpenAI Configuration (for Chatbot)
```env
AZURE_OPENAI_API_KEY=your_azure_openai_api_key
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4o-mini
AZURE_OPENAI_API_VERSION=2024-02-15-preview
```

### OpenAI Configuration (for Voice Agent LLM)
```env
OPENAI_API_KEY=your_openai_api_key
```

## ğŸš€ Setup Instructions

### 1. Backend Setup

#### LiveKit Voice Agent

```bash
cd backend/livekit-voice-agent

# Install dependencies using uv
uv sync

# Create .env.local file with required environment variables
# (See Environment Variables section above)
```

#### Token Server

```bash
cd backend/token-server

# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Frontend Setup

```bash
cd frontend

# Install dependencies
npm install
```

## â–¶ï¸ Running the Project

### Terminal 1: LiveKit Voice Agent
```bash
cd backend/livekit-voice-agent
uv run livekit-agents dev
```

### Terminal 2: Token Server (FastAPI)
```bash
cd backend/token-server
# Activate virtual environment first
python server.py
# Or use uvicorn directly:
uvicorn server:app --reload --port 8000
```

### Terminal 3: Frontend Development Server
```bash
cd frontend
npm run dev
```

The application will be available at `http://localhost:5173` (or the port shown in the terminal).

## ğŸ”Œ API Endpoints

### Token Server Endpoints

- `GET /api/token` - Generate LiveKit access token
  - Query params: `room_name` (default: "voice-assistant"), `participant_name` (default: "user")
  
- `POST /api/chat` - Send chat message to AI assistant
  - Body: `{ "message": "your message", "conversation_history": [...] }`
  - Response: `{ "response": "ai response" }`

- `GET /health` - Health check endpoint

## ğŸ—ï¸ Architecture

### Voice Assistant Flow

1. User clicks voice assistant button in the frontend
2. Frontend requests token from token server (`/api/token`)
3. Frontend connects to LiveKit room using the token
4. Voice agent (backend) joins the room when user starts speaking
5. Real-time audio streaming: User â†” LiveKit â†” Voice Agent
6. Voice agent processes audio, generates responses, and streams back

### Chatbot Flow

1. User sends message in chat interface
2. Frontend sends POST request to `/api/chat`
3. Token server forwards request to Azure OpenAI
4. Response is sent back to frontend and displayed

## ğŸ› ï¸ Technology Stack

- **Frontend**: React 18, Vite
- **Backend Voice Agent**: LiveKit Agents Framework, Python
- **Token Server**: FastAPI, Uvicorn
- **Voice Services**: 
  - LiveKit (real-time communication)
  - AssemblyAI (speech-to-text)
  - Cartesia (text-to-speech)
  - Silero (voice activity detection)
- **AI Services**:
  - Azure OpenAI (chatbot)
  - OpenAI GPT-4.1-mini (voice agent LLM)

## ğŸ“ Development Notes

- The voice agent uses multilingual turn detection for natural conversation flow
- Noise cancellation (BVC) is enabled for better audio quality
- Windows compatibility: Process timeout is set to 60 seconds (see `agent.py`)
- Token server loads environment variables from `../livekit-voice-agent/.env.local`

## ğŸ”’ Security Notes

- In production, update CORS settings in `token-server/server.py` to specify allowed origins
- Never commit `.env.local` files to version control
- Use secure API key storage and management in production

## ğŸ“š Additional Resources

- [LiveKit Documentation](https://docs.livekit.io/)
- [LiveKit Agents Documentation](https://docs.livekit.io/agents/)
- [Azure OpenAI Documentation](https://learn.microsoft.com/en-us/azure/ai-services/openai/)
- [React Documentation](https://react.dev/)

## ğŸ¤ Contributing

1. Ensure all environment variables are configured
2. Follow the existing code structure
3. Test voice and chat functionality before submitting changes

## ğŸ“„ License

[Add your license information here]

